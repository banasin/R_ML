# Установка и подключение библиотек
#install.packages("caret")
library("caret")
library("party")
library("randomForest")

# Загрузка данных и обработка пропущенных значений
getwd()
tr <- read.delim("Diabetes.txt", as.is = FALSE) 
tr <- na.omit(tr)  

# Разделение на обучающую и тестовую выборки
set.seed(123)  # Установка начального значения
mm <- createDataPartition(tr$Class, p = 0.7, list = FALSE)  # Создание индексов для разделения на обучающую и тестовую выборки
trry <- tr[mm, ]  # Создание обучающей выборки на основе индексов
trest <- tr[-mm, ]  # Создание тестовой выборки на основе индексов




# Модель дерева классификации
ttree <- ctree(Class ~ ., data = trry)  # Построение модели дерева классификации на обучающей выборке
plot(ttree, type = "simple")  # Визуализация дерева
# Наиболее важный признак находится в корне дерева 

# Оценка точности для класса "N" с помощью модели ctree
pred <- predict(ttree, newdata = trest)  # Прогнозирование на тестовой выборке с помощью модели
confusionMatrix(data = pred, reference = trest$Class, positive = "N")  # Оценка точности с помощью матрицы ошибок




# Модель случайного леса
rtree <- randomForest(Class ~ ., data = trry, ntree = 10000, importance = TRUE)  # Построение модели случайного леса на обучающей выборке
plot(rtree)  # Визуализация случайного леса
varImpPlot(rtree)  # Визуализация важности признаков в случайном лесе

# Оценка точности для класса "N" с помощью модели случайного леса
predd <- predict(rtree, newdata = trest)  # Прогнозирование на тестовой выборке с помощью модели случайного леса
confusionMatrix(data = predd, reference = trest$Class, positive = "N")  # Оценка точности с помощью матрицы ошибок




# Итоги:

# Модель Дерева Классификации (Ctree)
# Точность (Accuracy): 0.787 - 78.7% прогнозов модели верны.
# Чувствительность (Sensitivity) для класса 'N': 0.8667 - модель правильно идентифицирует 86.67% всех истинных случаев класса 'N'.
# Специфичность (Specificity): 0.6375 - модель правильно идентифицирует 63.75% всех истинных случаев, которые не принадлежат классу 'N'.
# Положительная предсказательная ценность (Positive Predictive Value, PPV): 0.8176 - когда модель предсказывает класс 'N', она правильна в 81.76% случаев.
# Отрицательная предсказательная ценность (Negative Predictive Value, NPV): 0.7183 - когда модель предсказывает класс, отличный от 'N', она правильна в 71.83% случаев.
# Сбалансированная точность (Balanced Accuracy): 0.7521 - усредненная точность между чувствительностью и специфичностью.

# Модель Случайного Леса (Random Forest)
# Точность (Accuracy): 0.7739 - 77.39% прогнозов модели верны.
# Чувствительность (Sensitivity) для класса 'N': 0.8867 - модель правильно идентифицирует 88.67% всех истинных случаев класса 'N'.
# Специфичность (Specificity): 0.5625 - модель правильно идентифицирует 56.25% всех истинных случаев, которые не принадлежат классу 'N'.
# Положительная предсказательная ценность (PPV): 0.7917 - когда модель предсказывает класс 'N', она правильна в 79.17% случаев.
# Отрицательная предсказательная ценность (NPV): 0.7258 - когда модель предсказывает класс, отличный от 'N', она правильна в 72.58% случаев.
# Сбалансированная точность (Balanced Accuracy): 0.7246

# Сравнение моделей
# # Модель дерева классификации имеет более высокую общую точность, чем модель случайного леса.
# Модель случайного леса показывает более высокую чувствительность, но меньшую специфичность.
# Положительная и отрицательная предсказательные ценности у обеих моделей схожи, хотя модель дерева классификации немного круче.